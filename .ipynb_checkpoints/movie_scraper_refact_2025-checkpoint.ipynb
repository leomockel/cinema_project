{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8e7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import tqdm\n",
    "from urllib.request import Request, urlopen\n",
    "import os\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b522cf-2897-46ad-a05d-c5023a1524cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url, headers):\n",
    "    req = Request(url, headers=headers)\n",
    "    return BeautifulSoup(urlopen(req).read(), \"html.parser\")\n",
    "\n",
    "def parse_json_ld(soup):\n",
    "    script_tag = soup.find('script', {'type': 'application/ld+json'})\n",
    "    if not script_tag:\n",
    "        return {}\n",
    "    return json.loads(script_tag.string)\n",
    "\n",
    "def get_year(soup):\n",
    "    for link in soup.find_all('a', {'class': re.compile('ipc-link')}):\n",
    "        if link.text[:2] in (\"19\", \"20\"):\n",
    "            return int(link.text[:4])\n",
    "    return None\n",
    "\n",
    "def get_production_info(soup):\n",
    "    companies = soup.find_all('a', {'href': re.compile('company')})\n",
    "    \n",
    "    if \"Production compan\" not in companies[0].text:\n",
    "        prod_names = []\n",
    "    else :\n",
    "        prod_names = [c.text for c in companies if \"IMDbPro\" not in c.text and c.text != \"\" and \"Production compan\" not in c.text]\n",
    "        \n",
    "    prod_codes = [str(c).split(\"company/\")[1].split(\"/?ref\")[0] for c in companies if \"company/\" in str(c)]\n",
    "        \n",
    "    return prod_names, prod_codes\n",
    "\n",
    "def parse_duration(duration):\n",
    "    duration = duration.replace(\"PT\", \"\")\n",
    "\n",
    "    hours = 0\n",
    "    minutes = 0\n",
    "\n",
    "    if \"H\" in duration:\n",
    "        try:\n",
    "            hours = int(duration.split(\"H\")[0])\n",
    "            duration = duration.split(\"H\")[1]\n",
    "        except ValueError:\n",
    "            hours = 0\n",
    "\n",
    "    if \"M\" in duration:\n",
    "        try:\n",
    "            minutes = int(duration.split(\"M\")[0])\n",
    "        except ValueError:\n",
    "            minutes = 0\n",
    "\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "def get_cast_and_director(soup):\n",
    "    sections = soup.select('[class=\"ipc-page-section ipc-page-section--base ipc-page-section--bp-none\"]')\n",
    "\n",
    "    dir_section = None\n",
    "    cast_section = None\n",
    "\n",
    "    for section in sections:\n",
    "        head = section.find('div', {\"class\": re.compile(\"ipc-title__wrapper\")})\n",
    "        \n",
    "        if dir_section != None and cast_section != None:\n",
    "            break\n",
    "        elif \"Director\" in [a.text.strip() for a in head][0]:\n",
    "            dir_section = section\n",
    "            directors = [d.text.strip() for d in dir_section.find_all('a', {\"class\": re.compile(\"title-text-big\")})]\n",
    "            dir_codes = [a['href'].split('/')[2] for a in dir_section.find_all('a', {\"class\": re.compile(\"title-text-big\")})]\n",
    "        elif [a.text.strip() for a in head][0] == \"Cast\":\n",
    "            cast_section = section\n",
    "            actors = cast_section.find_all('a', {\"class\": re.compile(\"title-text-big\")})\n",
    "            cast_names = [a.text.strip() for a in actors]\n",
    "            cast_codes = [(str(actors[i]).split('/name/')[1]).split('/?ref')[0] for i in range(len(actors))]\n",
    "\n",
    "            spans = cast_section.findAll('span')\n",
    "            good_span = [span for span in spans if span.get_text(strip=True) != \"/\"]\n",
    "\n",
    "            cast_voice = []\n",
    "            for idx, span in enumerate(good_span):\n",
    "                if \"ipc-metadata-list-summary-item__t\" not in span.get(\"class\", []):\n",
    "                    continue\n",
    "\n",
    "                if idx == len(good_span) - 1:\n",
    "                    cast_voice.append(\"A\")\n",
    "                    continue\n",
    "\n",
    "                next_text = good_span[idx + 1].get_text(strip=True).lower()\n",
    "\n",
    "                if \"(voice)\" in next_text:\n",
    "                    cast_voice.append(\"V\")\n",
    "                elif \"uncredited\" in next_text:\n",
    "                    cast_voice.append(\"U\")\n",
    "                else:\n",
    "                    cast_voice.append(\"A\")\n",
    "\n",
    "            mask = [el != \"U\" for el in cast_voice]\n",
    "            cast_names = [cast_names[i] for i in range(len(mask)) if mask[i]]\n",
    "            cast_codes = [cast_codes[i] for i in range(len(mask)) if mask[i]]\n",
    "            cast_voice = [cast_voice[i] for i in range(len(mask)) if mask[i]]\n",
    "\n",
    "            if len(cast_names) > 30:\n",
    "                cast_names, cast_codes, cast_voice = cast_names[:30], cast_codes[:30], cast_voice[:30]\n",
    "\n",
    "    return cast_names, cast_codes, cast_voice, directors, dir_codes\n",
    "\n",
    "def get_budget(soup):\n",
    "    try:\n",
    "        spans = soup.find_all('span', {'class': 'ipc-metadata-list-item__list-content-item'})\n",
    "        budget_text = [s.text for s in spans if \"estimé\" in s.text][0]\n",
    "        parts = budget_text.replace(\"\\u202f\", \"\").replace(\"\\xa0\", \" \").split(\" \")\n",
    "        return int(parts[0]), parts[1]\n",
    "    except Exception:\n",
    "        return 0, \"\"\n",
    "\n",
    "def movie_imdb(imdb_id):\n",
    "    HEADERS = {\n",
    "      'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36',\n",
    "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "      'Accept-Encoding': 'none',\n",
    "      'Accept-Language': 'fr;q=0.9,en-US,en;q=0.8',\n",
    "      'Connection': 'keep-alive',\n",
    "      'refere': 'https://imdb.com'}\n",
    "    \n",
    "    # First page\n",
    "    soup = get_soup(f\"https://www.imdb.com/title/{imdb_id}/\", headers=HEADERS)\n",
    "    info = parse_json_ld(soup)\n",
    "    \n",
    "    original_title = info.get(\"name\", \"\")\n",
    "    rating = info.get(\"aggregateRating\", {}).get(\"ratingValue\", \"\")\n",
    "    num_rate = info.get(\"aggregateRating\", {}).get(\"ratingCount\", \"\")\n",
    "    year = get_year(soup)\n",
    "    duration = parse_duration(info.get(\"duration\", \"\"))\n",
    "    genres = info.get(\"genre\", [])\n",
    "    country = [c.text for c in soup.find_all('a', {'href': re.compile('country_of_origin')})] or [\"No Info\"]\n",
    "    country = [\"USA\" if c == \"United States\" else \"UK\" if c == \"United Kingdom\" else c for c in country]\n",
    "    language = [l.text for l in soup.find_all('a', {'href': re.compile('primary_language')})] or [\"No Info\"]\n",
    "    prod_names, prod_codes = get_production_info(soup)\n",
    "\n",
    "    # Full credits page\n",
    "    soup2 = get_soup(f\"https://www.imdb.com/title/{imdb_id}/fullcredits\", headers=HEADERS)\n",
    "    cast, cast_codes, cast_roles, directors, dir_codes = get_cast_and_director(soup2)\n",
    "\n",
    "    # Budget (French page)\n",
    "    HEADERS['Accept-Language'] = 'fr-CH, fr;q=0.9,en-US,en;q=0.8'\n",
    "    soup3 = get_soup(f\"https://www.imdb.com/title/{imdb_id}/\", headers=HEADERS)\n",
    "    info_fr = parse_json_ld(soup3)\n",
    "    title = info_fr.get(\"alternateName\", info_fr.get(\"name\", \"\"))\n",
    "    \n",
    "    errors = {\"&apos;\":\"'\",\"&amp;\":\"&\"}\n",
    "\n",
    "    for val in errors.keys():\n",
    "        original_title = original_title.replace(val, errors[val])\n",
    "        title = title.replace(val, errors[val])\n",
    "        \n",
    "    budget, bud_currency = get_budget(soup3)\n",
    "\n",
    "    if rating != \"\":\n",
    "        return imdb_id, title, original_title, year, directors, dir_codes, cast, cast_codes, cast_roles, genres, duration, \\\n",
    "           country, language, prod_names, prod_codes, rating, num_rate, budget, bud_currency\n",
    "    else:\n",
    "        return imdb_id, title,\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bff422f-f14a-4e57-a0e3-9a1859a91df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def get_movies_multithread(imdb_ids, max_workers=10):\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(movie_imdb, imdb_id): imdb_id for imdb_id in imdb_ids}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            imdb_id = futures[future]\n",
    "\n",
    "            data = future.result()\n",
    "            results.append(data)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b3326b-da8d-413f-8e7e-bd45d0d8657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import movies to scrap\n",
    "df = pd.read_csv('movies_to_scrap/scrap_it.csv', encoding=\"ISO-8859-1\", sep=\";\")\n",
    "imdb_id = df[\"imdb\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4777f67f-c235-4137-a3e5-e2fadea139f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_df = pd.read_csv('db_backup/movies_db.csv', encoding=\"ISO-8859-1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "796ea0d2-737c-4171-9096-eb3c61556ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_db = db_df[\"movie_id\"].values\n",
    "final_imdb = [i for i in imdb_id if i not in imdb_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25aa5e77-fb3c-4e5f-999c-c8a500672e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_imdb = list(set(final_imdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1a911b-576f-4603-8be9-62adafb30a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies = get_movies_multithread(final_imdb, max_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e37f169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.DataFrame(movies,columns = [\"movie_id\",\"french_title\",\"original_title\",\"year\",\"director\",\"director_id\",\\\n",
    "                                          \"actor\",\"actor_id\",\"status\",\"genre\",\"duration\",\"country\",\\\n",
    "                                          \"language\",\"production\",\"prod_id\",\"rating\",\"num_rate\",\\\n",
    "                                          \"budget\",\"currency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ed3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep movies with a rating (the other are probably not available)\n",
    "movie_keep = movie_df.drop(movie_df[movie_df[\"year\"] == \"\"].index).reset_index(drop=True)\n",
    "too_soon = pd.DataFrame(movie_df[[\"movie_id\",\"french_title\"]].drop(movie_df[movie_df[\"year\"] != \"\"].index).values, \\\n",
    "            columns= ['imdb_id', 'title']).set_index(\"imdb_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b6f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scraped movies with no ratings\n",
    "if len(too_soon) > 0:\n",
    "    f_scrap = pd.read_csv('movies_to_scrap/too_soon.csv', encoding=\"ISO-8859-1\", sep=\";\").set_index(\"imdb_id\")\n",
    "    too_soon = pd.concat([f_scrap, too_soon])\n",
    "    too_soon.to_csv('movies_to_scrap/too_soon.csv', encoding=\"ISO-8859-1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e571a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "changer = {\"$US\":1, \"$CA\":0.72, \"$AU\":0.65, \"€\":1.08, \"£GB\":1.29, \"₩\":0.00073, \"₹\":0.012, \"CNY\":0.14, \"RUR\":0.011, \\\n",
    "          \"CZK\":0.043, \"NOK\":0.092, \"BDT\":0.0085, \"HKD\":0.13, \"R$\":0.162, \"CHF\":0.8, \"MYR\":0.24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef467819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_keep[\"def_budget\"] = movie_keep[\"budget\"] * movie_keep[\"currency\"].apply(lambda x : changer[x] if x != \"\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d23029",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_keep[\"def_budget\"] = movie_keep[\"def_budget\"].apply(lambda x: int(x) if x !=0 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83232e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifs = [\"actor\",\"country\",\"director\",\"genre\",\"language\",\"production\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fee7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in modifs:\n",
    "    movie_keep[f\"{mod}s\"] = movie_keep[mod].apply(lambda x : \" | \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "002ce24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_keep[\"saw\"] = False\n",
    "movie_keep[\"wishlist\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da8bcde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = movie_keep[[\"movie_id\",\"saw\",\"wishlist\",\"french_title\",\"original_title\",\"year\",\"directors\",\"actors\",\"genres\",\\\n",
    "                     \"duration\",\"countrys\",\"languages\",\"productions\",\"rating\",\"num_rate\",\"def_budget\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10e6fbdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select.to_excel(\"movies_scraped.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9fae801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# update movies_db\n",
    "up_movies = select[[\"movie_id\",\"french_title\",\"original_title\",\"year\",\"duration\",\"rating\",\"num_rate\",\"def_budget\"]]\\\n",
    "                    .set_index(\"movie_id\").rename(columns = {\"def_budget\":\"budget\"})\n",
    "up_movies.to_csv(\"update_db/up_movies.csv\", encoding=\"ISO-8859-1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3757f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update user_db\n",
    "up_user = select[[\"movie_id\",\"saw\",\"wishlist\"]].set_index(\"movie_id\")\n",
    "up_user.to_csv(\"update_db/up_user.csv\", encoding=\"ISO-8859-1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b4a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = pd.read_csv(\"db_backup/genres_db.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b69b1a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genre_dict = dict(zip(genre_df[\"name\"], genre_df[\"genre_id\"]))\n",
    "genre_dict[\"\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62cf1c45-a98b-4bc2-9b66-e2dd6cea5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_genre_df = movie_keep[[\"movie_id\",\"genre\"]].explode([\"genre\"], ignore_index=True)\n",
    "tot_genre_df = tot_genre_df.fillna(\"\")\n",
    "tot_genre_df[\"genre_id\"] = tot_genre_df[\"genre\"].apply(lambda x: genre_dict[x])\n",
    "tot_genre_df = tot_genre_df.drop([\"genre\"], axis=1).drop_duplicates()\n",
    "tot_genre_df = tot_genre_df[tot_genre_df[\"genre_id\"].notna() & (tot_genre_df[\"genre_id\"] != \"\")]\n",
    "tot_genre_df.set_index(\"movie_id\").to_csv(\"update_db/up_movie_genre.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78140b4-39cf-4496-83ad-09fe4d3dcc7f",
   "metadata": {},
   "source": [
    "### Update actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0f77156-a9a3-4d54-84a4-d17283bfe978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot_actor_df = movie_keep[[\"movie_id\",\"actor\", \"actor_id\", \"status\"]].explode([\"actor\", \"actor_id\", \"status\"], ignore_index=True)\n",
    "tot_actor_df[\"status\"] = tot_actor_df[\"status\"].str.replace(\"A\", \"\", regex=False)\n",
    "tot_actor_final = tot_actor_df.drop([\"actor\"], axis=1).drop_duplicates()\n",
    "tot_actor_final = tot_actor_final[tot_actor_final[\"actor_id\"].notna() & (tot_actor_final[\"actor_id\"].str.strip() != \"\")]\n",
    "tot_actor_final.set_index(\"movie_id\").to_csv(\"update_db/up_movie_actor.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7abffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_db = pd.read_csv(f'db_backup/actors_db.csv', encoding=\"ISO-8859-1\", sep=\";\")\n",
    "\n",
    "actors_df = tot_actor_df.drop([\"movie_id\", \"status\"], axis=1).drop_duplicates()\n",
    "new_actors = actors_df[~actors_df[\"actor_id\"].isin(act_db[\"actor_id\"])]\n",
    "if len(new_actors) != 0:\n",
    "    new_actors.columns = [\"name\",\"actor_id\"]\n",
    "    new_actors.set_index(\"actor_id\").to_csv(\"update_db/up_actor.csv\", encoding=\"ISO-8859-1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab9215",
   "metadata": {},
   "source": [
    "### Update director and production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "091c109b-a7e8-431a-a65a-254062eed7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dict = {\"dir\":[\"director\",\"director_id\"],\"prod\":[\"production\",\"prod_id\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ce1052f-d8f5-4ef1-bddc-b8efbbca77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in db_dict.items():\n",
    "    tot_df = movie_keep[[\"movie_id\",v[0], v[1]]].explode([v[0], v[1]], ignore_index=True)\n",
    "    tot_df_final = tot_df.drop([v[0]], axis=1).drop_duplicates()\n",
    "    tot_df_final = tot_df_final[tot_df_final[v[1]].notna() & (tot_df_final[v[1]].str.strip() != \"\")]\n",
    "    tot_df_final.set_index(\"movie_id\").to_csv(f\"update_db/up_movie_{k}.csv\", sep=\";\")\n",
    "\n",
    "    val_db = pd.read_csv(f'db_backup/{v[0]}_db.csv', encoding=\"ISO-8859-1\", sep=\";\")\n",
    "    \n",
    "    val_df = tot_df.drop([\"movie_id\"], axis=1).drop_duplicates()\n",
    "    new_val = val_df[~val_df[v[1]].isin(val_db[v[1]])]\n",
    "    if len(new_val) != 0:\n",
    "        new_val.columns = [\"name\",v[1]]\n",
    "        new_val.set_index(v[1]).to_csv(f\"update_db/up_{v[0]}.csv\", encoding=\"ISO-8859-1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434a168",
   "metadata": {},
   "source": [
    "### Update Country and Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa2ddb05-8b64-4e79-a1fb-07d27c9c351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_list = [\"country\", \"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f43f0c3-5cae-4db7-95aa-ca0ebdd0b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_id(name):\n",
    "    global max_id\n",
    "    if name not in info_dict.keys():\n",
    "        max_id += 1\n",
    "        info_dict[name] = max_id\n",
    "    return info_dict[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0fa84e1-ff7e-40ab-9aec-0ec9dc7115f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in db_list:\n",
    "    val_db2 = pd.read_csv(f'db_backup/{val}_db.csv', encoding=\"ISO-8859-1\", sep=\";\")\n",
    "    info_dict = dict(zip(val_db2[\"name\"], val_db2[f\"{val}_id\"]))\n",
    "    max_id = max(val_db2[f\"{val}_id\"])\n",
    "    \n",
    "    tot_df2 = movie_keep[[\"movie_id\",val]].explode([val], ignore_index=True)\n",
    "    tot_df2[f\"{val}_id\"] = tot_df2[val].apply(get_or_create_id)\n",
    "    tot_df2.columns = [\"movie_id\",\"name\",f\"{val}_id\"]\n",
    "    tot_df2_final = tot_df2.drop(\"name\", axis=1).drop_duplicates()\n",
    "    tot_df2_final = tot_df2_final[tot_df2_final[f\"{val}_id\"].notna() & (tot_df2_final[f\"{val}_id\"] != \"\")]\n",
    "    tot_df2_final.set_index(\"movie_id\").to_csv(f\"update_db/up_movie_{val}.csv\", sep=\";\")\n",
    "    \n",
    "    val_df2 = tot_df2.drop([\"movie_id\"], axis=1).drop_duplicates()\n",
    "    new_val2 = tot_df2[~tot_df2[f\"{val}_id\"].isin(val_db2[f\"{val}_id\"])]\n",
    "    if len(new_val2) != 0:\n",
    "        new_val2.set_index(f\"{val}_id\").to_csv(f\"update_db/up_{val}.csv\", encoding=\"ISO-8859-1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d7fb9a1-4c93-4055-aab4-9cc03b410ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2b0673-ea78-4e43-b7fb-0a5cd52887f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabdaf17-fdef-4f11-9126-8919f055adb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a44b1d-de07-4b0a-b6ec-06f20c41e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d5b4271-76ac-4e71-8676-c3eb77c29813",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9df85252",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_file = {\"movies_db\":[\"up_movies\", \"movie_id\", \"movies\"], \"actors_db\":[\"up_actor\", \"actor_id\", \"actors\"], \\\n",
    "             \"country_db\":[\"up_country\", \"country_id\", \"country\"], \"director_db\":[\"up_director\", \"director_id\",\"directors\"], \\\n",
    "             \"genres_db\":[\"up_genre\", \"genre_id\", \"genres\"], \"language_db\":[\"up_language\", \"language_id\", \"language\"], \\\n",
    "             \"production_db\":[\"up_production\", \"prod_id\", \"production\"],\"movie_actor_db_2\":[\"up_movie_actor\", \"movie_id\", \"movie_actor\"], \\\n",
    "             \"movie_country_db\":[\"up_movie_country\", \"movie_id\", \"movie_country\"], \"movie_dir_db\":[\"up_movie_dir\", \"movie_id\", \"movie_director\"], \\\n",
    "             \"movie_genre_db\":[\"up_movie_genre\", \"movie_id\", \"movie_genre\"], \"movie_language_db\":[\"up_movie_language\", \"movie_id\", \"movie_language\"], \\\n",
    "             \"movie_prod_db\":[\"up_movie_prod\", \"movie_id\", \"movie_prod\"], \"user_list_db\":[\"up_user\", \"movie_id\", \"user_list\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baa425e0-ffd0-4232-87e5-56c94d85ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict_file.items():\n",
    "    if os.path.isfile(f\"update_db/{value[0]}.csv\"):\n",
    "        database = pd.read_csv(f\"db_backup/{key}.csv\",encoding=\"ISO-8859-1\", sep=\";\").set_index(value[1])\n",
    "        up = pd.read_csv(f\"update_db/{value[0]}.csv\",encoding=\"ISO-8859-1\", sep=\";\").set_index(value[1])\n",
    "        up.to_sql(value[2], engine, if_exists=\"append\")\n",
    "        pd.concat([database, up]).to_csv(f\"db_backup/{key}.csv\",encoding=\"ISO-8859-1\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
